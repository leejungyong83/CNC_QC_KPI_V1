"""
ê³ ê¸‰ ë²ˆì—­ ìºì‹± ì‹œìŠ¤í…œ
ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ë‹¤ì¸µ ìºì‹œ êµ¬ì¡° ë° ì••ì¶• ê¸°ëŠ¥
"""

import json
import hashlib
import time
import gzip
import pickle
from typing import Dict, Any, Optional, Tuple, List
from functools import lru_cache
from collections import OrderedDict
import streamlit as st
import threading

class AdvancedTranslationCache:
    """ê³ ê¸‰ ë²ˆì—­ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_memory_size: int = 1000, max_disk_size: int = 10000):
        self.max_memory_size = max_memory_size
        self.max_disk_size = max_disk_size
        
        # ë©”ëª¨ë¦¬ ìºì‹œ (LRU)
        self.memory_cache: OrderedDict = OrderedDict()
        
        # ë””ìŠ¤í¬ ìºì‹œ (ì„¸ì…˜ ê¸°ë°˜)
        self.disk_cache_key = "advanced_translation_cache"
        
        # í†µê³„ ì •ë³´
        self.stats = {
            "memory_hits": 0,
            "disk_hits": 0,
            "api_calls": 0,
            "cache_saves": 0,
            "total_requests": 0,
            "avg_response_time": 0.0
        }
        
        # ìŠ¤ë ˆë“œ ì•ˆì „ì„±ì„ ìœ„í•œ ë½
        self._lock = threading.Lock()
        
        # ì´ˆê¸°í™”ì‹œ ë””ìŠ¤í¬ ìºì‹œ ë¡œë“œ
        self._load_disk_cache()
    
    def _generate_cache_key(self, text: str, source_lang: str, target_lang: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„± (í•´ì‹œ ê¸°ë°˜)"""
        key_string = f"{text}|{source_lang}|{target_lang}"
        return hashlib.md5(key_string.encode('utf-8')).hexdigest()
    
    def _compress_data(self, data: Any) -> bytes:
        """ë°ì´í„° ì••ì¶•"""
        try:
            json_str = json.dumps(data, ensure_ascii=False)
            return gzip.compress(json_str.encode('utf-8'))
        except Exception:
            # JSON ì§ë ¬í™” ì‹¤íŒ¨ ì‹œ pickle ì‚¬ìš©
            return gzip.compress(pickle.dumps(data))
    
    def _decompress_data(self, compressed_data: bytes) -> Any:
        """ë°ì´í„° ì••ì¶• í•´ì œ"""
        try:
            decompressed = gzip.decompress(compressed_data)
            try:
                return json.loads(decompressed.decode('utf-8'))
            except json.JSONDecodeError:
                return pickle.loads(decompressed)
        except Exception:
            return None
    
    def _load_disk_cache(self):
        """ë””ìŠ¤í¬ ìºì‹œ ë¡œë“œ (ì„¸ì…˜ ìƒíƒœì—ì„œ)"""
        try:
            if self.disk_cache_key in st.session_state:
                compressed_cache = st.session_state[self.disk_cache_key]
                disk_cache = self._decompress_data(compressed_cache)
                
                if disk_cache and isinstance(disk_cache, dict):
                    # ë§Œë£Œëœ í•­ëª© ì œê±°
                    current_time = time.time()
                    valid_cache = {}
                    
                    for key, (data, timestamp, ttl) in disk_cache.items():
                        if current_time - timestamp < ttl:
                            valid_cache[key] = (data, timestamp, ttl)
                    
                    # ë©”ëª¨ë¦¬ ìºì‹œì— ì¼ë¶€ ë¡œë“œ (ìµœì‹  í•­ëª© ìš°ì„ )
                    sorted_items = sorted(valid_cache.items(), 
                                        key=lambda x: x[1][1], reverse=True)
                    
                    for key, (data, timestamp, ttl) in sorted_items[:self.max_memory_size//2]:
                        self.memory_cache[key] = (data, timestamp, ttl)
                        
        except Exception as e:
            print(f"ë””ìŠ¤í¬ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _save_disk_cache(self):
        """ë””ìŠ¤í¬ ìºì‹œ ì €ì¥ (ì„¸ì…˜ ìƒíƒœì—)"""
        try:
            with self._lock:
                # ë©”ëª¨ë¦¬ ìºì‹œì™€ ê¸°ì¡´ ë””ìŠ¤í¬ ìºì‹œ ë³‘í•©
                disk_cache = {}
                
                # ê¸°ì¡´ ë””ìŠ¤í¬ ìºì‹œ ë¡œë“œ
                if self.disk_cache_key in st.session_state:
                    try:
                        existing_cache = self._decompress_data(st.session_state[self.disk_cache_key])
                        if existing_cache:
                            disk_cache.update(existing_cache)
                    except Exception:
                        pass
                
                # ë©”ëª¨ë¦¬ ìºì‹œ ì¶”ê°€
                disk_cache.update(dict(self.memory_cache))
                
                # í¬ê¸° ì œí•œ ì ìš©
                if len(disk_cache) > self.max_disk_size:
                    # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
                    sorted_items = sorted(disk_cache.items(), 
                                        key=lambda x: x[1][1], reverse=True)
                    disk_cache = dict(sorted_items[:self.max_disk_size])
                
                # ì••ì¶•í•˜ì—¬ ì €ì¥
                compressed_cache = self._compress_data(disk_cache)
                st.session_state[self.disk_cache_key] = compressed_cache
                
                self.stats["cache_saves"] += 1
                
        except Exception as e:
            print(f"ë””ìŠ¤í¬ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get(self, text: str, source_lang: str, target_lang: str) -> Optional[str]:
        """ìºì‹œì—ì„œ ë²ˆì—­ ì¡°íšŒ"""
        start_time = time.time()
        cache_key = self._generate_cache_key(text, source_lang, target_lang)
        
        try:
            with self._lock:
                self.stats["total_requests"] += 1
                
                # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
                if cache_key in self.memory_cache:
                    data, timestamp, ttl = self.memory_cache[cache_key]
                    
                    if time.time() - timestamp < ttl:
                        # LRU ì—…ë°ì´íŠ¸
                        self.memory_cache.move_to_end(cache_key)
                        self.stats["memory_hits"] += 1
                        
                        response_time = time.time() - start_time
                        self._update_avg_response_time(response_time)
                        
                        return data
                    else:
                        # ë§Œë£Œëœ í•­ëª© ì œê±°
                        del self.memory_cache[cache_key]
                
                # 2. ë””ìŠ¤í¬ ìºì‹œ í™•ì¸
                if self.disk_cache_key in st.session_state:
                    try:
                        disk_cache = self._decompress_data(st.session_state[self.disk_cache_key])
                        
                        if disk_cache and cache_key in disk_cache:
                            data, timestamp, ttl = disk_cache[cache_key]
                            
                            if time.time() - timestamp < ttl:
                                # ë©”ëª¨ë¦¬ ìºì‹œë¡œ ìŠ¹ê²©
                                self._add_to_memory_cache(cache_key, data, timestamp, ttl)
                                self.stats["disk_hits"] += 1
                                
                                response_time = time.time() - start_time
                                self._update_avg_response_time(response_time)
                                
                                return data
                    except Exception:
                        pass
                
                return None
                
        except Exception as e:
            print(f"ìºì‹œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None
    
    def set(self, text: str, source_lang: str, target_lang: str, 
            translation: str, ttl: int = 3600):
        """ë²ˆì—­ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥"""
        cache_key = self._generate_cache_key(text, source_lang, target_lang)
        timestamp = time.time()
        
        try:
            with self._lock:
                self._add_to_memory_cache(cache_key, translation, timestamp, ttl)
                
                # ì£¼ê¸°ì ìœ¼ë¡œ ë””ìŠ¤í¬ì— ì €ì¥ (ë§¤ 10ë²ˆì§¸ë§ˆë‹¤)
                if self.stats["cache_saves"] % 10 == 0:
                    self._save_disk_cache()
                    
        except Exception as e:
            print(f"ìºì‹œ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def _add_to_memory_cache(self, key: str, data: str, timestamp: float, ttl: int):
        """ë©”ëª¨ë¦¬ ìºì‹œì— ì¶”ê°€ (LRU ê´€ë¦¬)"""
        # í¬ê¸° ì œí•œ í™•ì¸
        if len(self.memory_cache) >= self.max_memory_size:
            # ê°€ì¥ ì˜¤ë˜ëœ í•­ëª© ì œê±°
            self.memory_cache.popitem(last=False)
        
        self.memory_cache[key] = (data, timestamp, ttl)
    
    def _update_avg_response_time(self, response_time: float):
        """í‰ê·  ì‘ë‹µ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        current_avg = self.stats["avg_response_time"]
        total_requests = self.stats["total_requests"]
        
        if total_requests == 1:
            self.stats["avg_response_time"] = response_time
        else:
            # ì´ë™ í‰ê·  ê³„ì‚°
            self.stats["avg_response_time"] = (current_avg * (total_requests - 1) + response_time) / total_requests
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ë°˜í™˜"""
        total_hits = self.stats["memory_hits"] + self.stats["disk_hits"]
        total_requests = self.stats["total_requests"]
        
        hit_rate = (total_hits / total_requests * 100) if total_requests > 0 else 0
        
        return {
            **self.stats,
            "memory_cache_size": len(self.memory_cache),
            "hit_rate": round(hit_rate, 2),
            "memory_hit_rate": round(self.stats["memory_hits"] / total_requests * 100, 2) if total_requests > 0 else 0,
            "disk_hit_rate": round(self.stats["disk_hits"] / total_requests * 100, 2) if total_requests > 0 else 0,
            "avg_response_time_ms": round(self.stats["avg_response_time"] * 1000, 2)
        }
    
    def clear_cache(self, cache_type: str = "all"):
        """ìºì‹œ ì‚­ì œ"""
        try:
            with self._lock:
                if cache_type in ["all", "memory"]:
                    self.memory_cache.clear()
                
                if cache_type in ["all", "disk"]:
                    if self.disk_cache_key in st.session_state:
                        del st.session_state[self.disk_cache_key]
                
                # í†µê³„ ì´ˆê¸°í™”
                if cache_type == "all":
                    self.stats = {
                        "memory_hits": 0,
                        "disk_hits": 0,
                        "api_calls": 0,
                        "cache_saves": 0,
                        "total_requests": 0,
                        "avg_response_time": 0.0
                    }
                    
        except Exception as e:
            print(f"ìºì‹œ ì‚­ì œ ì˜¤ë¥˜: {e}")
    
    def optimize_cache(self):
        """ìºì‹œ ìµœì í™” (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…)"""
        try:
            with self._lock:
                current_time = time.time()
                
                # ë§Œë£Œëœ ë©”ëª¨ë¦¬ ìºì‹œ í•­ëª© ì œê±°
                expired_keys = []
                for key, (data, timestamp, ttl) in self.memory_cache.items():
                    if current_time - timestamp >= ttl:
                        expired_keys.append(key)
                
                for key in expired_keys:
                    del self.memory_cache[key]
                
                # ë””ìŠ¤í¬ ìºì‹œ ì €ì¥
                self._save_disk_cache()
                
        except Exception as e:
            print(f"ìºì‹œ ìµœì í™” ì˜¤ë¥˜: {e}")

# ì „ì—­ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤
_global_cache = None

def get_advanced_cache() -> AdvancedTranslationCache:
    """ì „ì—­ ê³ ê¸‰ ìºì‹œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _global_cache
    if _global_cache is None:
        _global_cache = AdvancedTranslationCache()
    return _global_cache

@lru_cache(maxsize=100)
def get_cached_translation_fast(text: str, source_lang: str, target_lang: str) -> Optional[str]:
    """ë¹ ë¥¸ ìºì‹œ ì¡°íšŒ (LRU ë°ì½”ë ˆì´í„° ì‚¬ìš©)"""
    cache = get_advanced_cache()
    return cache.get(text, source_lang, target_lang)

def cache_translation(text: str, source_lang: str, target_lang: str, translation: str):
    """ë²ˆì—­ ê²°ê³¼ ìºì‹œ ì €ì¥"""
    cache = get_advanced_cache()
    cache.set(text, source_lang, target_lang, translation)
    
    # LRU ìºì‹œë„ ì—…ë°ì´íŠ¸
    get_cached_translation_fast.cache_clear()

def get_cache_performance_report() -> Dict[str, Any]:
    """ìºì‹œ ì„±ëŠ¥ ë³´ê³ ì„œ ìƒì„±"""
    cache = get_advanced_cache()
    stats = cache.get_stats()
    
    # ì„±ëŠ¥ ë“±ê¸‰ ê³„ì‚°
    hit_rate = stats["hit_rate"]
    if hit_rate >= 90:
        performance_grade = "ğŸŸ¢ Excellent"
    elif hit_rate >= 70:
        performance_grade = "ğŸŸ¡ Good"
    elif hit_rate >= 50:
        performance_grade = "ğŸŸ  Average"
    else:
        performance_grade = "ğŸ”´ Poor"
    
    return {
        **stats,
        "performance_grade": performance_grade,
        "recommendations": _get_performance_recommendations(stats)
    }

def _get_performance_recommendations(stats: Dict[str, Any]) -> List[str]:
    """ì„±ëŠ¥ ê°œì„  ê¶Œì¥ì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    if stats["hit_rate"] < 50:
        recommendations.append("ìºì‹œ í¬ê¸°ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”")
        recommendations.append("TTL ì‹œê°„ì„ ì¦ê°€ì‹œì¼œë³´ì„¸ìš”")
    
    if stats["avg_response_time_ms"] > 100:
        recommendations.append("ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”")
        recommendations.append("ìºì‹œ ìµœì í™”ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”")
    
    if stats["memory_hit_rate"] < 30:
        recommendations.append("ë©”ëª¨ë¦¬ ìºì‹œ í¬ê¸°ë¥¼ ëŠ˜ë ¤ë³´ì„¸ìš”")
    
    if not recommendations:
        recommendations.append("í˜„ì¬ ìµœì ì˜ ì„±ëŠ¥ì„ ë°œíœ˜í•˜ê³  ìˆìŠµë‹ˆë‹¤")
    
    return recommendations 